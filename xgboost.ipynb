{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga y preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FECHA</th>\n",
       "      <th>IRRADH00</th>\n",
       "      <th>IRRADH03</th>\n",
       "      <th>IRRADH06</th>\n",
       "      <th>IRRADH09</th>\n",
       "      <th>IRRADH12</th>\n",
       "      <th>IRRADH15</th>\n",
       "      <th>IRRADH18</th>\n",
       "      <th>IRRADH21</th>\n",
       "      <th>ANNO</th>\n",
       "      <th>MES</th>\n",
       "      <th>DIA</th>\n",
       "      <th>DIASEM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>589813.00</td>\n",
       "      <td>1294089.50</td>\n",
       "      <td>468098.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>438244.75</td>\n",
       "      <td>989406.00</td>\n",
       "      <td>272884.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>543215.75</td>\n",
       "      <td>1162550.80</td>\n",
       "      <td>359685.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>504131.56</td>\n",
       "      <td>1229353.20</td>\n",
       "      <td>460497.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>502349.70</td>\n",
       "      <td>1012553.75</td>\n",
       "      <td>391783.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        FECHA  IRRADH00  IRRADH03  IRRADH06   IRRADH09    IRRADH12   IRRADH15  \\\n",
       "0  2015-01-01       0.0       0.0       0.0  589813.00  1294089.50  468098.47   \n",
       "1  2015-01-02       0.0       0.0       0.0  438244.75   989406.00  272884.66   \n",
       "2  2015-01-03       0.0       0.0       0.0  543215.75  1162550.80  359685.12   \n",
       "3  2015-01-04       0.0       0.0       0.0  504131.56  1229353.20  460497.50   \n",
       "4  2015-01-05       0.0       0.0       0.0  502349.70  1012553.75  391783.16   \n",
       "\n",
       "   IRRADH18  IRRADH21  ANNO  MES  DIA  DIASEM  \n",
       "0       0.0       0.0  2015    1    1       3  \n",
       "1       0.0       0.0  2015    1    2       4  \n",
       "2       0.0       0.0  2015    1    3       5  \n",
       "3       0.0       0.0  2015    1    4       6  \n",
       "4       0.0       0.0  2015    1    5       0  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load file --------------------------------------------\n",
    "df_IRRAD = pd.read_csv('data/G04A_DATOS_IRRAD.csv', sep = \",\")\n",
    "df_IRRAD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FECHA</th>\n",
       "      <th>UTILH00</th>\n",
       "      <th>UTILH03</th>\n",
       "      <th>UTILH06</th>\n",
       "      <th>UTILH09</th>\n",
       "      <th>UTILH12</th>\n",
       "      <th>UTILH15</th>\n",
       "      <th>UTILH18</th>\n",
       "      <th>UTILH21</th>\n",
       "      <th>ANNO</th>\n",
       "      <th>MES</th>\n",
       "      <th>DIA</th>\n",
       "      <th>DIASEM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.053105</td>\n",
       "      <td>0.590946</td>\n",
       "      <td>0.615057</td>\n",
       "      <td>0.091254</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.048031</td>\n",
       "      <td>0.397291</td>\n",
       "      <td>0.396714</td>\n",
       "      <td>0.048448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049542</td>\n",
       "      <td>0.557435</td>\n",
       "      <td>0.604719</td>\n",
       "      <td>0.091748</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014918</td>\n",
       "      <td>0.375060</td>\n",
       "      <td>0.547907</td>\n",
       "      <td>0.090296</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.016370</td>\n",
       "      <td>0.167025</td>\n",
       "      <td>0.246309</td>\n",
       "      <td>0.051614</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        FECHA   UTILH00   UTILH03   UTILH06   UTILH09   UTILH12   UTILH15  \\\n",
       "0  2015-01-01  0.000023  0.000008  0.053105  0.590946  0.615057  0.091254   \n",
       "1  2015-01-02  0.000012  0.000004  0.048031  0.397291  0.396714  0.048448   \n",
       "2  2015-01-03  0.000008  0.000000  0.049542  0.557435  0.604719  0.091748   \n",
       "3  2015-01-04  0.000008  0.000000  0.014918  0.375060  0.547907  0.090296   \n",
       "4  2015-01-05  0.000008  0.000008  0.016370  0.167025  0.246309  0.051614   \n",
       "\n",
       "    UTILH18   UTILH21  ANNO  MES  DIA  DIASEM  \n",
       "0  0.000008  0.000019  2015    1    1       3  \n",
       "1  0.000000  0.000008  2015    1    2       4  \n",
       "2  0.000004  0.000004  2015    1    3       5  \n",
       "3  0.000016  0.000023  2015    1    4       6  \n",
       "4  0.000004  0.000000  2015    1    5       0  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load file --------------------------------------------\n",
    "df_UTIL = pd.read_csv('data/G04A_DATOS_UTIL.csv', sep = \",\")\n",
    "df_UTIL.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unimos todo en un mismo dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = pd.merge(df_IRRAD, df_UTIL, on='FECHA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FECHA</th>\n",
       "      <th>IRRADH00</th>\n",
       "      <th>IRRADH03</th>\n",
       "      <th>IRRADH06</th>\n",
       "      <th>IRRADH09</th>\n",
       "      <th>IRRADH12</th>\n",
       "      <th>IRRADH15</th>\n",
       "      <th>IRRADH18</th>\n",
       "      <th>IRRADH21</th>\n",
       "      <th>ANNO_x</th>\n",
       "      <th>...</th>\n",
       "      <th>UTILH06</th>\n",
       "      <th>UTILH09</th>\n",
       "      <th>UTILH12</th>\n",
       "      <th>UTILH15</th>\n",
       "      <th>UTILH18</th>\n",
       "      <th>UTILH21</th>\n",
       "      <th>ANNO_y</th>\n",
       "      <th>MES_y</th>\n",
       "      <th>DIA_y</th>\n",
       "      <th>DIASEM_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>589813.00</td>\n",
       "      <td>1294089.50</td>\n",
       "      <td>468098.470</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053105</td>\n",
       "      <td>0.590946</td>\n",
       "      <td>0.615057</td>\n",
       "      <td>0.091254</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>438244.75</td>\n",
       "      <td>989406.00</td>\n",
       "      <td>272884.660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048031</td>\n",
       "      <td>0.397291</td>\n",
       "      <td>0.396714</td>\n",
       "      <td>0.048448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>543215.75</td>\n",
       "      <td>1162550.80</td>\n",
       "      <td>359685.120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049542</td>\n",
       "      <td>0.557435</td>\n",
       "      <td>0.604719</td>\n",
       "      <td>0.091748</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>504131.56</td>\n",
       "      <td>1229353.20</td>\n",
       "      <td>460497.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014918</td>\n",
       "      <td>0.375060</td>\n",
       "      <td>0.547907</td>\n",
       "      <td>0.090296</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>502349.70</td>\n",
       "      <td>1012553.75</td>\n",
       "      <td>391783.160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016370</td>\n",
       "      <td>0.167025</td>\n",
       "      <td>0.246309</td>\n",
       "      <td>0.051614</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>2020-12-27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176437.95</td>\n",
       "      <td>596362.94</td>\n",
       "      <td>213554.200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012102</td>\n",
       "      <td>0.068252</td>\n",
       "      <td>0.070849</td>\n",
       "      <td>0.012841</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>573497.50</td>\n",
       "      <td>1097877.50</td>\n",
       "      <td>269206.560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032334</td>\n",
       "      <td>0.334919</td>\n",
       "      <td>0.285503</td>\n",
       "      <td>0.046018</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>425860.56</td>\n",
       "      <td>801252.40</td>\n",
       "      <td>237152.560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023633</td>\n",
       "      <td>0.245105</td>\n",
       "      <td>0.282372</td>\n",
       "      <td>0.017419</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214860.45</td>\n",
       "      <td>321715.56</td>\n",
       "      <td>29951.986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010654</td>\n",
       "      <td>0.134742</td>\n",
       "      <td>0.076885</td>\n",
       "      <td>0.005577</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274070.03</td>\n",
       "      <td>355043.44</td>\n",
       "      <td>72243.560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022105</td>\n",
       "      <td>0.104125</td>\n",
       "      <td>0.109311</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2192 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           FECHA  IRRADH00  IRRADH03  IRRADH06   IRRADH09    IRRADH12  \\\n",
       "0     2015-01-01       0.0       0.0       0.0  589813.00  1294089.50   \n",
       "1     2015-01-02       0.0       0.0       0.0  438244.75   989406.00   \n",
       "2     2015-01-03       0.0       0.0       0.0  543215.75  1162550.80   \n",
       "3     2015-01-04       0.0       0.0       0.0  504131.56  1229353.20   \n",
       "4     2015-01-05       0.0       0.0       0.0  502349.70  1012553.75   \n",
       "...          ...       ...       ...       ...        ...         ...   \n",
       "2187  2020-12-27       0.0       0.0       0.0  176437.95   596362.94   \n",
       "2188  2020-12-28       0.0       0.0       0.0  573497.50  1097877.50   \n",
       "2189  2020-12-29       0.0       0.0       0.0  425860.56   801252.40   \n",
       "2190  2020-12-30       0.0       0.0       0.0  214860.45   321715.56   \n",
       "2191  2020-12-31       0.0       0.0       0.0  274070.03   355043.44   \n",
       "\n",
       "        IRRADH15  IRRADH18  IRRADH21  ANNO_x  ...   UTILH06   UTILH09  \\\n",
       "0     468098.470       0.0       0.0    2015  ...  0.053105  0.590946   \n",
       "1     272884.660       0.0       0.0    2015  ...  0.048031  0.397291   \n",
       "2     359685.120       0.0       0.0    2015  ...  0.049542  0.557435   \n",
       "3     460497.500       0.0       0.0    2015  ...  0.014918  0.375060   \n",
       "4     391783.160       0.0       0.0    2015  ...  0.016370  0.167025   \n",
       "...          ...       ...       ...     ...  ...       ...       ...   \n",
       "2187  213554.200       0.0       0.0    2020  ...  0.012102  0.068252   \n",
       "2188  269206.560       0.0       0.0    2020  ...  0.032334  0.334919   \n",
       "2189  237152.560       0.0       0.0    2020  ...  0.023633  0.245105   \n",
       "2190   29951.986       0.0       0.0    2020  ...  0.010654  0.134742   \n",
       "2191   72243.560       0.0       0.0    2020  ...  0.022105  0.104125   \n",
       "\n",
       "       UTILH12   UTILH15   UTILH18   UTILH21  ANNO_y  MES_y  DIA_y  DIASEM_y  \n",
       "0     0.615057  0.091254  0.000008  0.000019    2015      1      1         3  \n",
       "1     0.396714  0.048448  0.000000  0.000008    2015      1      2         4  \n",
       "2     0.604719  0.091748  0.000004  0.000004    2015      1      3         5  \n",
       "3     0.547907  0.090296  0.000016  0.000023    2015      1      4         6  \n",
       "4     0.246309  0.051614  0.000004  0.000000    2015      1      5         0  \n",
       "...        ...       ...       ...       ...     ...    ...    ...       ...  \n",
       "2187  0.070849  0.012841  0.000003  0.000003    2020     12     27         6  \n",
       "2188  0.285503  0.046018  0.000003  0.000007    2020     12     28         0  \n",
       "2189  0.282372  0.017419  0.000007  0.000007    2020     12     29         1  \n",
       "2190  0.076885  0.005577  0.000010  0.000000    2020     12     30         2  \n",
       "2191  0.109311  0.018283  0.000010  0.000010    2020     12     31         3  \n",
       "\n",
       "[2192 rows x 25 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos el melt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vars = ['FECHA', 'ANNO_x', 'MES_x', 'DIA_x', 'DIASEM_x']\n",
    "\n",
    "irrad_melt = pd.melt(df_aux, id_vars=id_vars, value_vars=['IRRADH00', 'IRRADH03', 'IRRADH06', 'IRRADH09', 'IRRADH12', 'IRRADH15', 'IRRADH18', 'IRRADH21'], var_name='HOUR', value_name='IRRAD_VALUE')\n",
    "\n",
    "util_melt = pd.melt(df_aux, id_vars=id_vars, value_vars=['UTILH00', 'UTILH03', 'UTILH06', 'UTILH09', 'UTILH12', 'UTILH15', 'UTILH18', 'UTILH21'], var_name='HOUR', value_name='UTIL_VALUE')\n",
    "\n",
    "irrad_melt['HOUR'] = irrad_melt['HOUR'].str.extract('(\\d+)')\n",
    "util_melt['HOUR'] = util_melt['HOUR'].str.extract('(\\d+)')\n",
    "\n",
    "df = pd.merge(irrad_melt, util_melt, on=id_vars + ['HOUR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FECHA</th>\n",
       "      <th>ANNO_x</th>\n",
       "      <th>MES_x</th>\n",
       "      <th>DIA_x</th>\n",
       "      <th>DIASEM_x</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>IRRAD_VALUE</th>\n",
       "      <th>UTIL_VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17531</th>\n",
       "      <td>2020-12-27</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17532</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17533</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17534</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17535</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17536 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            FECHA  ANNO_x  MES_x  DIA_x  DIASEM_x HOUR  IRRAD_VALUE  \\\n",
       "0      2015-01-01    2015      1      1         3   00          0.0   \n",
       "1      2015-01-02    2015      1      2         4   00          0.0   \n",
       "2      2015-01-03    2015      1      3         5   00          0.0   \n",
       "3      2015-01-04    2015      1      4         6   00          0.0   \n",
       "4      2015-01-05    2015      1      5         0   00          0.0   \n",
       "...           ...     ...    ...    ...       ...  ...          ...   \n",
       "17531  2020-12-27    2020     12     27         6   21          0.0   \n",
       "17532  2020-12-28    2020     12     28         0   21          0.0   \n",
       "17533  2020-12-29    2020     12     29         1   21          0.0   \n",
       "17534  2020-12-30    2020     12     30         2   21          0.0   \n",
       "17535  2020-12-31    2020     12     31         3   21          0.0   \n",
       "\n",
       "       UTIL_VALUE  \n",
       "0        0.000023  \n",
       "1        0.000012  \n",
       "2        0.000008  \n",
       "3        0.000008  \n",
       "4        0.000008  \n",
       "...           ...  \n",
       "17531    0.000003  \n",
       "17532    0.000007  \n",
       "17533    0.000007  \n",
       "17534    0.000000  \n",
       "17535    0.000010  \n",
       "\n",
       "[17536 rows x 8 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede visualizar como la variable fecha, tiene una periodicidad por año, por tanto borramos esta variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['DIASEM_x'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FECHA</th>\n",
       "      <th>ANNO_x</th>\n",
       "      <th>MES_x</th>\n",
       "      <th>DIA_x</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>IRRAD_VALUE</th>\n",
       "      <th>UTIL_VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17531</th>\n",
       "      <td>2020-12-27</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17532</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17533</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17534</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17535</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17536 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            FECHA  ANNO_x  MES_x  DIA_x HOUR  IRRAD_VALUE  UTIL_VALUE\n",
       "0      2015-01-01    2015      1      1   00          0.0    0.000023\n",
       "1      2015-01-02    2015      1      2   00          0.0    0.000012\n",
       "2      2015-01-03    2015      1      3   00          0.0    0.000008\n",
       "3      2015-01-04    2015      1      4   00          0.0    0.000008\n",
       "4      2015-01-05    2015      1      5   00          0.0    0.000008\n",
       "...           ...     ...    ...    ...  ...          ...         ...\n",
       "17531  2020-12-27    2020     12     27   21          0.0    0.000003\n",
       "17532  2020-12-28    2020     12     28   21          0.0    0.000007\n",
       "17533  2020-12-29    2020     12     29   21          0.0    0.000007\n",
       "17534  2020-12-30    2020     12     30   21          0.0    0.000000\n",
       "17535  2020-12-31    2020     12     31   21          0.0    0.000010\n",
       "\n",
       "[17536 rows x 7 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUIDADO CON EL TEMA DEL ONE HOT ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           FECHA  ANNO_x  MES_x  DIA_x HOUR  IRRAD_VALUE  UTIL_VALUE  dia_mes\n",
      "0     2015-01-01    2015      1      1   00          0.0    0.000023        1\n",
      "1     2015-01-02    2015      1      2   00          0.0    0.000012        2\n",
      "2     2015-01-03    2015      1      3   00          0.0    0.000008        3\n",
      "3     2015-01-04    2015      1      4   00          0.0    0.000008        4\n",
      "4     2015-01-05    2015      1      5   00          0.0    0.000008        5\n",
      "...          ...     ...    ...    ...  ...          ...         ...      ...\n",
      "17531 2020-12-27    2020     12     27   21          0.0    0.000003      362\n",
      "17532 2020-12-28    2020     12     28   21          0.0    0.000007      363\n",
      "17533 2020-12-29    2020     12     29   21          0.0    0.000007      364\n",
      "17534 2020-12-30    2020     12     30   21          0.0    0.000000      365\n",
      "17535 2020-12-31    2020     12     31   21          0.0    0.000010      366\n",
      "\n",
      "[17536 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "df['FECHA'] = pd.to_datetime(df['FECHA'])\n",
    "\n",
    "df['dia_mes'] = df['FECHA'].dt.dayofyear\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANNO_x</th>\n",
       "      <th>MES_x</th>\n",
       "      <th>DIA_x</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>IRRAD_VALUE</th>\n",
       "      <th>UTIL_VALUE</th>\n",
       "      <th>dia_mes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17531</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17532</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17533</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17534</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17535</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17536 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ANNO_x  MES_x  DIA_x HOUR  IRRAD_VALUE  UTIL_VALUE  dia_mes\n",
       "0        2015      1      1   00          0.0    0.000023        1\n",
       "1        2015      1      2   00          0.0    0.000012        2\n",
       "2        2015      1      3   00          0.0    0.000008        3\n",
       "3        2015      1      4   00          0.0    0.000008        4\n",
       "4        2015      1      5   00          0.0    0.000008        5\n",
       "...       ...    ...    ...  ...          ...         ...      ...\n",
       "17531    2020     12     27   21          0.0    0.000003      362\n",
       "17532    2020     12     28   21          0.0    0.000007      363\n",
       "17533    2020     12     29   21          0.0    0.000007      364\n",
       "17534    2020     12     30   21          0.0    0.000000      365\n",
       "17535    2020     12     31   21          0.0    0.000010      366\n",
       "\n",
       "[17536 rows x 7 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['FECHA'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('UTIL_VALUE', axis=1)\n",
    "y = df['UTIL_VALUE']\n",
    "\n",
    "X['HOUR'] = pd.to_numeric(X['HOUR'], errors='coerce')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento (valores faltantes o categóricos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Asignación de características numéricas y definición de su transformador\n",
    "# Excluye las columnas que se tratarán como categóricas\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.drop(['ANNO_x', 'MES_x', 'DIA_x', 'HOUR'])\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Asignación de características categóricas explícitas\n",
    "categorical_features = ['ANNO_x', 'MES_x', 'DIA_x', 'HOUR']\n",
    "\n",
    "# Definición del transformador categórico con imputación y codificación One-Hot\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Si las columnas ya son de tipo numérico, cámbialas a tipo object para tratarlas como categóricas.\n",
    "for col in categorical_features:\n",
    "    X_train[col] = X_train[col].astype('object')\n",
    "    X_test[col] = X_test[col].astype('object')\n",
    "\n",
    "# Preprocesador que aplica las transformaciones numéricas y categóricas\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Aplicación del preprocesador a los conjuntos de datos de entrenamiento y prueba\n",
    "X_train_prep = preprocessor.fit_transform(X_train)\n",
    "X_test_prep = preprocessor.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "model.fit(X_train_prep, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0045, RMSE: 0.0673, R^2: 0.9252\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_prep)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.4f}, RMSE: {rmse:.4f}, R^2: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01111417, -0.00164817,  0.76935613, ...,  0.01272914,\n",
       "        0.00261259,  0.5818022 ], dtype=float32)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste fino de hiperparámetros (Gridsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 175 candidates, totalling 525 fits\n",
      "[CV] END ..learning_rate=0.01, max_depth=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=1, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=1, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=1, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=1, n_estimators=400; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=1, n_estimators=400; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=1, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=1, n_estimators=400; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=1, n_estimators=500; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=1, n_estimators=500; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=1, n_estimators=500; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=2, n_estimators=400; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=2, n_estimators=400; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=2, n_estimators=400; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=400; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=400; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=400; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=500; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=500; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=500; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=400; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=400; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=400; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=500; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=500; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=500; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=400; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=400; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=400; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=500; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=500; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=500; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=300; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=300; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=300; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=400; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=400; total time=   0.5s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=400; total time=   0.5s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=500; total time=   0.5s\n",
      "[CV] END ..learning_rate=0.05, max_depth=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=500; total time=   0.5s\n",
      "[CV] END ..learning_rate=0.05, max_depth=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.05, max_depth=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=500; total time=   0.5s\n",
      "[CV] END ..learning_rate=0.05, max_depth=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.05, max_depth=1, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=300; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.05, max_depth=1, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=1, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=300; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.05, max_depth=1, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=1, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=1, n_estimators=400; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=300; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.05, max_depth=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.05, max_depth=1, n_estimators=400; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=1, n_estimators=400; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=1, n_estimators=500; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.05, max_depth=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.05, max_depth=1, n_estimators=500; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=1, n_estimators=500; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=400; total time=   0.6s\n",
      "[CV] END ..learning_rate=0.05, max_depth=2, n_estimators=400; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=400; total time=   0.6s\n",
      "[CV] END ..learning_rate=0.05, max_depth=2, n_estimators=400; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=2, n_estimators=400; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=400; total time=   0.7s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=500; total time=   0.7s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=500; total time=   0.8s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=7, n_estimators=500; total time=   0.8s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=400; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=400; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=400; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=500; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=500; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=3, n_estimators=500; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=400; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=400; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=400; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=500; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=500; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.05, max_depth=4, n_estimators=500; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=400; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=400; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.05, max_depth=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=500; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=400; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.05, max_depth=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=500; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.05, max_depth=5, n_estimators=500; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.05, max_depth=6, n_estimators=300; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.05, max_depth=6, n_estimators=300; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.05, max_depth=6, n_estimators=300; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.05, max_depth=6, n_estimators=400; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.05, max_depth=6, n_estimators=400; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.05, max_depth=6, n_estimators=400; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.05, max_depth=6, n_estimators=500; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.05, max_depth=6, n_estimators=500; total time=   0.5s\n",
      "[CV] END ..learning_rate=0.05, max_depth=6, n_estimators=500; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=300; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=300; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=300; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=1, n_estimators=300; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=1, n_estimators=300; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=1, n_estimators=300; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=1, n_estimators=400; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=1, n_estimators=400; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=1, n_estimators=400; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=1, n_estimators=500; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=1, n_estimators=500; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=400; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=1, n_estimators=500; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=400; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=400; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=2, n_estimators=400; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=500; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=2, n_estimators=400; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=2, n_estimators=400; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=500; total time=   0.6s\n",
      "[CV] END ..learning_rate=0.05, max_depth=7, n_estimators=500; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=300; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=400; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=400; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=400; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=500; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=500; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=500; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=400; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=400; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=400; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=500; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=500; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=500; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=400; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=400; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=400; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=500; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=500; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=300; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=300; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=500; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=300; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=400; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=400; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=400; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=500; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.15, max_depth=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=500; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=500; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.15, max_depth=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.15, max_depth=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.15, max_depth=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.15, max_depth=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.15, max_depth=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=300; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=300; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.15, max_depth=1, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=1, n_estimators=300; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.15, max_depth=1, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=1, n_estimators=400; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=1, n_estimators=400; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=1, n_estimators=400; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=300; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.15, max_depth=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.15, max_depth=1, n_estimators=500; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.15, max_depth=1, n_estimators=500; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.15, max_depth=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.15, max_depth=1, n_estimators=500; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.15, max_depth=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=400; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=400; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=400; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.15, max_depth=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.15, max_depth=2, n_estimators=400; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=2, n_estimators=400; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.15, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.15, max_depth=2, n_estimators=400; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=3, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=3, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=3, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=500; total time=   0.5s\n",
      "[CV] END ..learning_rate=0.15, max_depth=3, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=3, n_estimators=300; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=500; total time=   0.6s\n",
      "[CV] END ..learning_rate=0.15, max_depth=3, n_estimators=300; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=7, n_estimators=500; total time=   0.6s\n",
      "[CV] END ..learning_rate=0.15, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.15, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=3, n_estimators=400; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=3, n_estimators=400; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=3, n_estimators=400; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.15, max_depth=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=3, n_estimators=500; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.15, max_depth=3, n_estimators=500; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.15, max_depth=3, n_estimators=500; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.15, max_depth=4, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=4, n_estimators=300; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.15, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=4, n_estimators=400; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.15, max_depth=4, n_estimators=400; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.15, max_depth=4, n_estimators=400; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.15, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=4, n_estimators=500; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.15, max_depth=4, n_estimators=500; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.15, max_depth=4, n_estimators=500; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.15, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.15, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.15, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.15, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=5, n_estimators=400; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.15, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=5, n_estimators=400; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.15, max_depth=5, n_estimators=400; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.15, max_depth=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.15, max_depth=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.15, max_depth=5, n_estimators=500; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.15, max_depth=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.15, max_depth=5, n_estimators=500; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.15, max_depth=5, n_estimators=500; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.15, max_depth=7, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=6, n_estimators=300; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.15, max_depth=6, n_estimators=300; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.15, max_depth=6, n_estimators=300; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.15, max_depth=7, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=7, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=6, n_estimators=400; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.15, max_depth=6, n_estimators=400; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.15, max_depth=6, n_estimators=400; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.15, max_depth=7, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.15, max_depth=7, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.15, max_depth=6, n_estimators=500; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.15, max_depth=7, n_estimators=200; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.15, max_depth=6, n_estimators=500; total time=   0.5s\n",
      "[CV] END ..learning_rate=0.15, max_depth=6, n_estimators=500; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.2, max_depth=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.15, max_depth=7, n_estimators=300; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.15, max_depth=7, n_estimators=300; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.15, max_depth=7, n_estimators=300; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=1, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=1, n_estimators=300; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=1, n_estimators=300; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=1, n_estimators=300; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=1, n_estimators=400; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=1, n_estimators=400; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=1, n_estimators=400; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=1, n_estimators=500; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.15, max_depth=7, n_estimators=400; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.2, max_depth=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=1, n_estimators=500; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=7, n_estimators=400; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.2, max_depth=1, n_estimators=500; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=7, n_estimators=400; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.2, max_depth=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=2, n_estimators=300; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=2, n_estimators=400; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=2, n_estimators=400; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=2, n_estimators=400; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=7, n_estimators=500; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.15, max_depth=7, n_estimators=500; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.2, max_depth=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.15, max_depth=7, n_estimators=500; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=300; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=400; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=400; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=400; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=500; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=500; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=500; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=400; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=400; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=400; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=500; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=500; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=500; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=400; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=400; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=400; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=500; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=500; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=500; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=300; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=300; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=300; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=400; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=400; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=400; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=500; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=500; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=500; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=300; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=300; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=300; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=400; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=400; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=400; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=500; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=500; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=7, n_estimators=500; total time=   0.4s\n",
      "Mejores parámetros: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    # Aumenta en incrementos más pequeños, pero aún significativos para ver el efecto.\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [1, 2, 3, 4, 5, 6, 7],\n",
    "    # Añade más valores para una búsqueda más granular, pero mantén el incremento razonable.\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "\n",
    "grid_search.fit(X_train_prep, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f'Mejores parámetros: {grid_search.best_params_}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación final del modelo ajustado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (ajustado): 0.0043, RMSE (ajustado): 0.0657, R^2 (ajustado): 0.9286\n"
     ]
    }
   ],
   "source": [
    "y_pred_best = best_model.predict(X_test_prep)\n",
    "\n",
    "mse_best = mean_squared_error(y_test, y_pred_best)\n",
    "rmse_best = mse_best ** 0.5\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(f\"MSE (ajustado): {mse_best:.4f}, RMSE (ajustado): {rmse_best:.4f}, R^2 (ajustado): {r2_best:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Feature  Importance\n",
      "55      HOUR_15    0.301562\n",
      "0   IRRAD_VALUE    0.241073\n",
      "52       HOUR_6    0.100924\n",
      "53       HOUR_9    0.065277\n",
      "54      HOUR_12    0.031085\n",
      "7       MES_x_1    0.014263\n",
      "8       MES_x_2    0.012303\n",
      "12      MES_x_6    0.011458\n",
      "16     MES_x_10    0.010589\n",
      "9       MES_x_3    0.010485\n",
      "15      MES_x_9    0.007870\n",
      "18     MES_x_12    0.007393\n",
      "31     DIA_x_13    0.006960\n",
      "11      MES_x_5    0.006667\n",
      "6   ANNO_x_2020    0.006304\n",
      "17     MES_x_11    0.006288\n",
      "10      MES_x_4    0.006095\n",
      "38     DIA_x_20    0.005567\n",
      "27      DIA_x_9    0.005492\n",
      "13      MES_x_7    0.005447\n",
      "14      MES_x_8    0.005438\n",
      "39     DIA_x_21    0.005359\n",
      "47     DIA_x_29    0.005337\n",
      "30     DIA_x_12    0.005293\n",
      "42     DIA_x_24    0.005215\n",
      "4   ANNO_x_2018    0.004954\n",
      "49     DIA_x_31    0.004674\n",
      "24      DIA_x_6    0.004541\n",
      "22      DIA_x_4    0.004516\n",
      "33     DIA_x_15    0.004438\n",
      "48     DIA_x_30    0.004319\n",
      "35     DIA_x_17    0.004301\n",
      "41     DIA_x_23    0.004113\n",
      "5   ANNO_x_2019    0.004032\n",
      "36     DIA_x_18    0.003956\n",
      "1   ANNO_x_2015    0.003946\n",
      "2   ANNO_x_2016    0.003868\n",
      "29     DIA_x_11    0.003769\n",
      "26      DIA_x_8    0.003728\n",
      "37     DIA_x_19    0.003695\n",
      "46     DIA_x_28    0.003560\n",
      "19      DIA_x_1    0.003501\n",
      "34     DIA_x_16    0.003497\n",
      "56      HOUR_18    0.003371\n",
      "32     DIA_x_14    0.003354\n",
      "45     DIA_x_27    0.003350\n",
      "43     DIA_x_25    0.003307\n",
      "28     DIA_x_10    0.003272\n",
      "20      DIA_x_2    0.003250\n",
      "3   ANNO_x_2017    0.003200\n",
      "21      DIA_x_3    0.003013\n",
      "40     DIA_x_22    0.002824\n",
      "44     DIA_x_26    0.002603\n",
      "25      DIA_x_7    0.002577\n",
      "23      DIA_x_5    0.002354\n",
      "51       HOUR_3    0.000231\n",
      "57      HOUR_21    0.000089\n",
      "50       HOUR_0    0.000054\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import plot_importance\n",
    "\n",
    "# Asigna los nombres de las características transformadas numéricas directamente\n",
    "transformed_numeric_features = numeric_features.tolist()\n",
    "\n",
    "# Obtiene los nombres de las características categóricas transformadas del one-hot encoder\n",
    "# Utiliza get_feature_names si estás utilizando una versión de scikit-learn < 0.22\n",
    "# o get_feature_names_out si estás utilizando scikit-learn >= 0.22\n",
    "transformed_categorical_features = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)\n",
    "\n",
    "# Combina los nombres de todas las características transformadas\n",
    "all_transformed_features = transformed_numeric_features + transformed_categorical_features.tolist()\n",
    "\n",
    "# Obtiene la importancia de las características del modelo XGBoost\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Crea un DataFrame con los nombres de las características y su importancia\n",
    "importances_df = pd.DataFrame({\n",
    "    'Feature': all_transformed_features,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Ordena las características por su importancia\n",
    "importances_df_sorted = importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Muestra las características más importantes\n",
    "print(importances_df_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filtrar las 10 características más importantes\n",
    "top_10_importances = importances_df_sorted.head(10)\n",
    "\n",
    "# Generar el gráfico de barras verticales\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=top_10_importances, y='Importance', x='Feature', palette=\"viridis\")\n",
    "plt.title('Top 10 Feature Importances')\n",
    "plt.ylabel('Importance')\n",
    "plt.xlabel('Feature')\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
